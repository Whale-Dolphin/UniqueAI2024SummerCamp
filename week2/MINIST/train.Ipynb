{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from net import MyLeNet\n",
    "# lr_scheduler: 提供根据epoch训练次数来调整学习率的方法\n",
    "from torch.optim import lr_scheduler\n",
    "import torchvision  \n",
    "from torch.utils.data import  DataLoader\n",
    "# transforms 主要用于一些常用的变换\n",
    "import torchvision.transforms as transforms\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 数据转换为tensor格式\n",
    "# Compose(): 将多个transforms的操作整合在一起\n",
    "# Totensor(): 将numpy()的ndarray或PIL.Image读的图片转换为(C,H,W)的Tensor格式，且归一化到(0,1.0)\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),  \n",
    "])\n",
    "\n",
    "train_dataset = torchvision.datasets.MNIST(root='./data/train', train=True,download=True,transform=transform)\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=16,shuffle=True)\n",
    "\n",
    "test_dataset = torchvision.datasets.MNIST(root='./data/test', train=False,download=True,transform=transform)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=16,shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 如果有英伟达显卡， 转到GPU上训练， 否则用CPU\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "# print(device) cuda\n",
    "\n",
    "# 将模型转到device上\n",
    "model = MyLeNet().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义损失函数（交叉熵损失函数）\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "# 定义优化器（随机梯度下降）\n",
    "optimizer = torch.optim.SGD(model.parameters(),lr=1e-3,momentum=0.9)\n",
    "\n",
    "# 定义lr_scheduler\n",
    "# StepLR：用于调整学习率， 一般会随着epoch的增加而减小学习率\n",
    "# 每10个epoch，学习率变为原来的0.1\n",
    "lr_scheduler = lr_scheduler.StepLR(optimizer,step_size=10,gamma=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义训练函数\n",
    "def train(dataloader,model,loss_fn,optimizer):\n",
    "    loss, current, n = 0.0 ,0.0, 0\n",
    "    \n",
    "    for batch, (x,y) in enumerate(dataloader):\n",
    "        # 将数据转到device上\n",
    "        x,y = x.to(device),y.to(device)\n",
    "        \n",
    "        # 前向传播\n",
    "        output = model(x)\n",
    "\n",
    "        # 计算观测值与训练值之间的损失函数\n",
    "        cur_loss = loss_fn(output,y)\n",
    "\n",
    "        # torch.max(input,dim)函数\n",
    "        # input为具体的tensor，dim是max函数索引的维度，0是每列的最大值，1是每行的最大值\n",
    "        # 函数会返回两个tensor，第一个tensor是每行的最大值，第二个tensor是每行最大值的索引\n",
    "        _, pred = torch.max(output, axis=1) \n",
    "\n",
    "        cur_acc = torch.sum(y == pred) / output.shape[0]\n",
    "\n",
    "        # 反向传播\n",
    "        # 清空过往梯度\n",
    "        optimizer.zero_grad()\n",
    "        # 反向传播,计算当前梯度\n",
    "        cur_loss.backward()\n",
    "        # 根据当前梯度优化参数\n",
    "        optimizer.step()\n",
    "        # .item():取出单元素的元素值，将其返回\n",
    "        loss += cur_loss\n",
    "        current += cur_acc\n",
    "        n += 1\n",
    "\n",
    "    train_loss = (loss / n)\n",
    "    train_acc = current / n\n",
    "    print('train_loss: ' + str(train_loss.item()))\n",
    "    print('train_acc ' +  str(train_acc.item()))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义验证函数\n",
    "def val(dataloader, model, loss_fn):\n",
    "    # 将模型设置为验证模式，以防改变权值\n",
    "    model.eval()\n",
    "    loss, current, n = 0.0, 0.0, 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch, (x,y) in enumerate(dataloader):\n",
    "            x,y = x.to(device),y.to(device)\n",
    "            output = model(x)\n",
    "            cur_loss = loss_fn(output,y)\n",
    "            _, pred = torch.max(output, axis=1) \n",
    "            cur_acc = torch.sum(y == pred) / output.shape[0]\n",
    "            loss += cur_loss\n",
    "            current += cur_acc\n",
    "            n += 1\n",
    "\n",
    "\n",
    "        print('val_loss: '+str(loss.item()/n))\n",
    "        print('val_acc: '+str(current.item()/n))\n",
    "        # 返回模型准确率\n",
    "        return current / n\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch1\n",
      "----------\n",
      "train_loss: 0.05663735792040825\n",
      "train_acc 0.9827333688735962\n",
      "val_loss: 0.04972222900390625\n",
      "val_acc: 0.9843\n",
      "save best model\n",
      "epoch2\n",
      "----------\n",
      "train_loss: 0.05509629845619202\n",
      "train_acc 0.9827499985694885\n",
      "val_loss: 0.04799354858398437\n",
      "val_acc: 0.9843\n",
      "epoch3\n",
      "----------\n",
      "train_loss: 0.05402019992470741\n",
      "train_acc 0.9833999872207642\n",
      "val_loss: 0.05158168334960937\n",
      "val_acc: 0.9836\n",
      "epoch4\n",
      "----------\n",
      "train_loss: 0.05272310599684715\n",
      "train_acc 0.9837666749954224\n",
      "val_loss: 0.04974171447753906\n",
      "val_acc: 0.9843\n",
      "epoch5\n",
      "----------\n",
      "train_loss: 0.051260050386190414\n",
      "train_acc 0.9842666983604431\n",
      "val_loss: 0.04655463256835937\n",
      "val_acc: 0.9848\n",
      "save best model\n",
      "epoch6\n",
      "----------\n",
      "train_loss: 0.05036832019686699\n",
      "train_acc 0.9843000173568726\n",
      "val_loss: 0.044907351684570315\n",
      "val_acc: 0.9848\n",
      "epoch7\n",
      "----------\n",
      "train_loss: 0.049182452261447906\n",
      "train_acc 0.9852833151817322\n",
      "val_loss: 0.04811090087890625\n",
      "val_acc: 0.9843\n",
      "epoch8\n",
      "----------\n",
      "train_loss: 0.04841326177120209\n",
      "train_acc 0.9853000044822693\n",
      "val_loss: 0.04297425537109375\n",
      "val_acc: 0.9866\n",
      "save best model\n",
      "epoch9\n",
      "----------\n",
      "train_loss: 0.047081902623176575\n",
      "train_acc 0.9853500127792358\n",
      "val_loss: 0.047450424194335934\n",
      "val_acc: 0.9833\n",
      "epoch10\n",
      "----------\n",
      "train_loss: 0.046893566846847534\n",
      "train_acc 0.9857500195503235\n",
      "val_loss: 0.04612327270507813\n",
      "val_acc: 0.9842\n",
      "epoch11\n",
      "----------\n",
      "train_loss: 0.04577723518013954\n",
      "train_acc 0.9862833619117737\n",
      "val_loss: 0.0489410400390625\n",
      "val_acc: 0.984\n",
      "epoch12\n",
      "----------\n",
      "train_loss: 0.044887740164995193\n",
      "train_acc 0.9861833453178406\n",
      "val_loss: 0.041910635375976564\n",
      "val_acc: 0.9862\n",
      "epoch13\n",
      "----------\n",
      "train_loss: 0.043687399476766586\n",
      "train_acc 0.9865000247955322\n",
      "val_loss: 0.03945157470703125\n",
      "val_acc: 0.9875\n",
      "save best model\n",
      "epoch14\n",
      "----------\n",
      "train_loss: 0.04310396686196327\n",
      "train_acc 0.9869000315666199\n",
      "val_loss: 0.03847488098144531\n",
      "val_acc: 0.9869\n",
      "epoch15\n",
      "----------\n",
      "train_loss: 0.04205220937728882\n",
      "train_acc 0.9869999885559082\n",
      "val_loss: 0.040638323974609376\n",
      "val_acc: 0.9864\n",
      "epoch16\n",
      "----------\n",
      "train_loss: 0.04175339266657829\n",
      "train_acc 0.9873666763305664\n",
      "val_loss: 0.03976055297851563\n",
      "val_acc: 0.9867\n",
      "epoch17\n",
      "----------\n",
      "train_loss: 0.04119137302041054\n",
      "train_acc 0.9871500134468079\n",
      "val_loss: 0.03950966796875\n",
      "val_acc: 0.9867\n",
      "epoch18\n",
      "----------\n",
      "train_loss: 0.04089855030179024\n",
      "train_acc 0.9869166612625122\n",
      "val_loss: 0.0434051025390625\n",
      "val_acc: 0.986\n",
      "epoch19\n",
      "----------\n",
      "train_loss: 0.03979283943772316\n",
      "train_acc 0.9877166748046875\n",
      "val_loss: 0.03897919006347656\n",
      "val_acc: 0.988\n",
      "save best model\n",
      "epoch20\n",
      "----------\n",
      "train_loss: 0.0391048789024353\n",
      "train_acc 0.98785001039505\n",
      "val_loss: 0.04104933471679687\n",
      "val_acc: 0.9863\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "# 开始训练\n",
    "epoch = 20\n",
    "max_acc = 0 # 记录当前最大的正确率，用于判断最佳模型\n",
    "for t in range(epoch):\n",
    "    print(f'epoch{t+1}\\n----------')\n",
    "    # 训练模型\n",
    "    train(train_dataloader,model,loss_fn,optimizer)\n",
    "    # 验证模型\n",
    "    acc = val(test_dataloader,model,loss_fn)\n",
    "    # 保存最好的权重模型\n",
    "    if acc > max_acc:\n",
    "        folder = 'save_model'\n",
    "        # path.exists: 判断括号里的文件是否存在，存在为True，括号内可以是文件路径\n",
    "        if not os.path.exists(folder):\n",
    "            # os.mkdir(): 用于数字权限模式创建目录\n",
    "            os.mkdir('save_model')\n",
    "        max_acc = acc\n",
    "        print('save best model')\n",
    "    # torch.save(state, dir)保存模型等相关的参数，dir表示保存文件的逻辑+保存文件名\n",
    "    # model.state_dict(): 返回的是一个OrderedDict，存储了网络结构的名字和对应的参数\n",
    "    torch.save(model.state_dict(),'save_model/best_model.pth')\n",
    "print('Done!')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "AI",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
