{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 调用需要的库\n",
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义 MLP 模型\n",
    "\n",
    "class MLP(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super(MLP, self).__init__()\n",
    "        self.hidden_layer = nn.Linear(input_size, hidden_size)\n",
    "        self.output_layer = nn.Linear(hidden_size, output_size)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.hidden_layer(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.output_layer(x)\n",
    "        x = self.sigmoid(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyDataset(Dataset):\n",
    "    def __init__(self, data, labels):\n",
    "        self.data = data\n",
    "        self.labels = labels\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        # if torch.is_tensor(idx):\n",
    "        #     idx = idx.tolist()\n",
    "        # 确保索引在范围内\n",
    "        if idx >= len(self.data):\n",
    "            raise IndexError(\"Index out of range\")\n",
    "        \n",
    "        sample = self.data.iloc[idx].values  # 按行号索引数据\n",
    "        label = self.labels.iloc[idx].values \n",
    "        \"\"\"\n",
    "        此处data为dataFrame类型,labels为Series类型\n",
    "        dataFrame和series类型经过切片之后均为series类型\n",
    "        此处.values将他们转换为numpy数组类型\n",
    "        \"\"\"\n",
    "\n",
    "        return sample, label\n",
    "\n",
    "def Standardization(data):\n",
    "    \"\"\"\n",
    "    标准化函数:将一组数据转化为均值为0,标准差为1的标准正态分布\n",
    "    \"\"\"\n",
    "    return (data-data.mean())/data.std()\n",
    "def Normolization(data):\n",
    "    \"\"\"\n",
    "    归一化函数：将一组数据按比例缩放到(0,1)\n",
    "    \"\"\"\n",
    "    return (data-data.min())/(data.max()-data.min())\n",
    "\n",
    "def train_test_split(X, y, test_size=0.2, random_state=None):\n",
    "    \"\"\"\n",
    "    将原有数据集拆分成数据集与测试集的函数\n",
    "    X: 特征向量\n",
    "    y: 标签值\n",
    "    test_size: test数据集占整个数据集的比例\n",
    "    randem_state: 随机种子\n",
    "    \"\"\"\n",
    "\n",
    "    # 设置随机种子\n",
    "    if random_state is not None:\n",
    "        np.random.seed(random_state)\n",
    "    \n",
    "    # 确定测试集的大小（样本数）\n",
    "    num_test = int(len(X) * test_size)\n",
    "    \n",
    "    # 生成随机索引\n",
    "    indices = np.random.permutation(len(X))\n",
    "    \n",
    "    # 切分数据集\n",
    "    X_train = X.iloc[indices[num_test:]]\n",
    "    X_test = X.iloc[indices[:num_test]]\n",
    "    y_train = y.iloc[indices[num_test:]]\n",
    "    y_test = y.iloc[indices[:num_test]]\n",
    "    \n",
    "    return X_train, X_test, y_train, y_test\n",
    "\n",
    "def data_preprocess(data_raw):\n",
    "    \"\"\"\n",
    "    数据预处理函数：\n",
    "        我们通过补中位数的方式,对age列进行补全\n",
    "        我们通过补众数的方式来,对Embarked进行补全\n",
    "        由于cabin缺了大部分数据,所以我们直接用U代表Unkown对其进行填补\n",
    "    \"\"\"\n",
    "    # 数据补全与特征缩放\n",
    "    data_raw['Age'].fillna(data_raw['Age'].median(),inplace=True)\n",
    "    data_raw['Embarked'] = data_raw['Embarked'].fillna(data_raw['Embarked'].mode().iloc[0]) \n",
    "    data_raw['Cabin'].fillna('U',inplace=True)\n",
    "    data_raw['Age']  = Standardization(data_raw['Age'])\n",
    "    data_raw['Fare']  = Standardization(data_raw['Fare'])\n",
    "\n",
    "    # 标签\n",
    "    target = ['Survived'] \n",
    "    y = data_raw[target]\n",
    "    # 用于预测的特征\n",
    "    fetures = ['Pclass','Sex','Age','Fare','Parch','SibSp','Embarked'] \n",
    "    X = pd.get_dummies(data_raw[fetures],dtype=int)\n",
    "    \n",
    "    return X,y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 主程序\n",
    "\n",
    "# 读取数据集\n",
    "data_raw = pd.read_csv(\"..\\week1\\dataProcess\\泰坦尼克号数据.csv\")\n",
    "\n",
    "# 数据预处理\n",
    "X, y = data_preprocess(data_raw)\n",
    "\n",
    "# 将数据集拆分成训练集与测试集\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0)\n",
    "\n",
    "# 制作数据集\n",
    "train_set = MyDataset(X_train, y_train)\n",
    "test_set = MyDataset(X_test, y_test)\n",
    "\n",
    "# 构造dataLoader\n",
    "batch_size = 32\n",
    "train_dataloader = DataLoader(dataset=train_set, batch_size=batch_size, shuffle=True, num_workers=0)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 实例化模型\n",
    "input_size = 10 # 输入特征数\n",
    "hidden_size = 3 # 隐藏神经元数\n",
    "output_size = 1 # 输出类别数\n",
    "model = MLP(input_size,hidden_size,output_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/1000], Loss: 0.7763\n",
      "Epoch [20/1000], Loss: 0.4132\n",
      "Epoch [30/1000], Loss: 0.2514\n",
      "Epoch [40/1000], Loss: 0.3584\n",
      "Epoch [50/1000], Loss: 0.2945\n",
      "Epoch [60/1000], Loss: 0.5126\n",
      "Epoch [70/1000], Loss: 0.1685\n",
      "Epoch [80/1000], Loss: 0.3682\n",
      "Epoch [90/1000], Loss: 0.1624\n",
      "Epoch [100/1000], Loss: 0.4804\n",
      "Epoch [110/1000], Loss: 0.4041\n",
      "Epoch [120/1000], Loss: 0.2678\n",
      "Epoch [130/1000], Loss: 0.3746\n",
      "Epoch [140/1000], Loss: 0.4208\n",
      "Epoch [150/1000], Loss: 0.2386\n",
      "Epoch [160/1000], Loss: 0.2942\n",
      "Epoch [170/1000], Loss: 0.8145\n",
      "Epoch [180/1000], Loss: 0.5073\n",
      "Epoch [190/1000], Loss: 0.2214\n",
      "Epoch [200/1000], Loss: 0.5488\n",
      "Epoch [210/1000], Loss: 0.7114\n",
      "Epoch [220/1000], Loss: 0.4448\n",
      "Epoch [230/1000], Loss: 0.4847\n",
      "Epoch [240/1000], Loss: 0.2743\n",
      "Epoch [250/1000], Loss: 0.3619\n",
      "Epoch [260/1000], Loss: 0.5608\n",
      "Epoch [270/1000], Loss: 0.2880\n",
      "Epoch [280/1000], Loss: 0.3903\n",
      "Epoch [290/1000], Loss: 0.3251\n",
      "Epoch [300/1000], Loss: 0.1892\n",
      "Epoch [310/1000], Loss: 0.3305\n",
      "Epoch [320/1000], Loss: 0.2525\n",
      "Epoch [330/1000], Loss: 0.3085\n",
      "Epoch [340/1000], Loss: 0.2573\n",
      "Epoch [350/1000], Loss: 0.7299\n",
      "Epoch [360/1000], Loss: 0.5229\n",
      "Epoch [370/1000], Loss: 0.5374\n",
      "Epoch [380/1000], Loss: 0.2285\n",
      "Epoch [390/1000], Loss: 0.6128\n",
      "Epoch [400/1000], Loss: 0.2381\n",
      "Epoch [410/1000], Loss: 0.3303\n",
      "Epoch [420/1000], Loss: 0.2475\n",
      "Epoch [430/1000], Loss: 0.6781\n",
      "Epoch [440/1000], Loss: 0.2358\n",
      "Epoch [450/1000], Loss: 0.3700\n",
      "Epoch [460/1000], Loss: 0.3521\n",
      "Epoch [470/1000], Loss: 0.7032\n",
      "Epoch [480/1000], Loss: 0.5952\n",
      "Epoch [490/1000], Loss: 0.3215\n",
      "Epoch [500/1000], Loss: 0.7921\n",
      "Epoch [510/1000], Loss: 0.6692\n",
      "Epoch [520/1000], Loss: 0.3221\n",
      "Epoch [530/1000], Loss: 0.2096\n",
      "Epoch [540/1000], Loss: 0.3402\n",
      "Epoch [550/1000], Loss: 0.2884\n",
      "Epoch [560/1000], Loss: 0.6501\n",
      "Epoch [570/1000], Loss: 0.5343\n",
      "Epoch [580/1000], Loss: 0.2897\n",
      "Epoch [590/1000], Loss: 0.4351\n",
      "Epoch [600/1000], Loss: 0.4577\n",
      "Epoch [610/1000], Loss: 0.5410\n",
      "Epoch [620/1000], Loss: 0.2437\n",
      "Epoch [630/1000], Loss: 0.2738\n",
      "Epoch [640/1000], Loss: 0.3226\n",
      "Epoch [650/1000], Loss: 0.2289\n",
      "Epoch [660/1000], Loss: 0.2801\n",
      "Epoch [670/1000], Loss: 0.7291\n",
      "Epoch [680/1000], Loss: 0.3894\n",
      "Epoch [690/1000], Loss: 0.4545\n",
      "Epoch [700/1000], Loss: 0.4053\n",
      "Epoch [710/1000], Loss: 0.4820\n",
      "Epoch [720/1000], Loss: 0.6130\n",
      "Epoch [730/1000], Loss: 0.1600\n",
      "Epoch [740/1000], Loss: 0.5311\n",
      "Epoch [750/1000], Loss: 0.1654\n",
      "Epoch [760/1000], Loss: 0.3427\n",
      "Epoch [770/1000], Loss: 0.4495\n",
      "Epoch [780/1000], Loss: 0.2000\n",
      "Epoch [790/1000], Loss: 0.8297\n",
      "Epoch [800/1000], Loss: 0.5083\n",
      "Epoch [810/1000], Loss: 0.1950\n",
      "Epoch [820/1000], Loss: 0.6245\n",
      "Epoch [830/1000], Loss: 0.3860\n",
      "Epoch [840/1000], Loss: 0.5030\n",
      "Epoch [850/1000], Loss: 0.5310\n",
      "Epoch [860/1000], Loss: 0.4568\n",
      "Epoch [870/1000], Loss: 0.1819\n",
      "Epoch [880/1000], Loss: 0.6403\n",
      "Epoch [890/1000], Loss: 0.5421\n",
      "Epoch [900/1000], Loss: 0.6583\n",
      "Epoch [910/1000], Loss: 0.2280\n",
      "Epoch [920/1000], Loss: 0.5734\n",
      "Epoch [930/1000], Loss: 0.1564\n",
      "Epoch [940/1000], Loss: 0.5305\n",
      "Epoch [950/1000], Loss: 0.3779\n",
      "Epoch [960/1000], Loss: 0.3092\n",
      "Epoch [970/1000], Loss: 0.4943\n",
      "Epoch [980/1000], Loss: 0.4741\n",
      "Epoch [990/1000], Loss: 0.4010\n",
      "Epoch [1000/1000], Loss: 0.2591\n"
     ]
    }
   ],
   "source": [
    "## 训练模型\n",
    "\n",
    "# 定义损失函数和优化器\n",
    "criterion = nn.BCELoss() # 二分类交叉熵损失\n",
    "optimizer = optim.Adam(model.parameters(),lr = 1e-5)\n",
    "\n",
    "# 训练模型\n",
    "epochs = 1000\n",
    "for epoch in range(epochs):\n",
    "    for X_batch,y_batch in train_dataloader:\n",
    "        # 确保输入数据是 Float 类型\n",
    "        X_batch = X_batch.float()\n",
    "        y_batch = y_batch.float()\n",
    "        \n",
    "        # 前向传播\n",
    "        y_hat = model(X_batch)\n",
    "\n",
    "        # 计算损失\n",
    "        loss = criterion(y_hat,y_batch)\n",
    "\n",
    "        # 反向传播与优化\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    \n",
    "    if (epoch + 1) % 10 == 0:\n",
    "        print(f'Epoch [{epoch+1}/{epochs}], Loss: {loss.item():.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 82.58%     Loss: 0.4009\n"
     ]
    }
   ],
   "source": [
    "# 模型评估\n",
    "model.eval()  # 设置模型为评估模式\n",
    "with torch.no_grad():\n",
    "    y_hat_test = model(torch.tensor(X_test.values,dtype=torch.float32))\n",
    "    y_hat_class = (y_hat_test > 0.5).float()\n",
    "    accuracy = (y_hat_class == torch.tensor(y_test.values,dtype=torch.float32)).float().mean()\n",
    "    test_loss = criterion(y_hat_test, torch.tensor(y_test.values,dtype=torch.float32))\n",
    "\n",
    "print(f'Accuracy: {accuracy * 100:.2f}%     Loss: {test_loss:.4f}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "AI",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
